sever.port=8080

langchain4j.open-ai.chat-model.base-url=https://dashscope.aliyuncs.com/compatible-mode/v1
langchain4j.open-ai.chat-model.api-key=sk-3a5b1753b99e45358a9ee2a4bdd1b53b
langchain4j.open-ai.chat-model.model-name=deepseek-v3
langchain4j.open-ai.chat-model.temperature=0.9

# ???????
langchain4j.open-ai.chat-model.log-requests=true
langchain4j.open-ai.chat-model.log-responses=true

#ollama
langchain4j.ollama.chat-model.base-url=http://localhost:11434
langchain4j.ollama.chat-model.model-name=deepseek-r1:1.5b
langchain4j.ollama.chat-model.log-requests=true
langchain4j.ollama.chat-model.log-responses=true

#??????
langchain4j.community.dashscope.chat-model.api-key=sk-3a5b1753b99e45358a9ee2a4bdd1b53b
langchain4j.community.dashscope.chat-model.model-name=qwen-max

#MongoDB????
spring.data.mongodb.uri=mongodb://localhost:27017/chat_memory_db

# ????debuge??
logging.level.root=debug